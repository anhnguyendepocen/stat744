---
title: "Approximate Bayesian Computation Lab"
author: "Kai Liu & Kavitha N."
date: "October 21, 2015"
output: pdf_document
---

# Preliminaries

There are two packages are available in R to implement approximate bayesian computations -- `abc` and `EasyABC`.


First, load the packages:

```{r loadpackage,cache=TRUE,message=FALSE}
library("abc")
library("EasyABC")
library("abc.data") ## load data package; automatically installed with abc
library("ggplot2")
```

# abc

```{r abcpackage,cache=TRUE}
data(musigma2)
data(human)
stat.voight
## ?stat.voight
par(mfcol = c(1,3), mar=c(5,3,4,.5)) 
boxplot(stat.3pops.sim[,"pi"]~models, main="Mean nucleotide diversity") 
boxplot(stat.3pops.sim[,"TajD.m"]~models, main="Mean Tajima's D") 
boxplot(stat.3pops.sim[,"TajD.v"]~models, main="Var in Tajima's D")
cv.modsel <- cv4postpr(models, stat.3pops.sim, nval=5,
                       tol=.01, method="mnlogistic") 
s <- summary(cv.modsel)
plot(cv.modsel, names.arg=c("Bottleneck", "Constant", "Exponential"))
modsel.ha <- postpr(stat.voight["hausa",], 
                    models, stat.3pops.sim, 
                    tol=.05, method="mnlogistic") 
modsel.it <- postpr(stat.voight["italian",], 
                    models, stat.3pops.sim, 
                    tol=.05, method="mnlogistic") 
modsel.ch <- postpr(stat.voight["chinese",], 
                    models, stat.3pops.sim, 
                    tol=.05, method="mnlogistic") 
summary(modsel.ha)
summary(modsel.it)

summary(modsel.ch)

res.gfit.bott=gfit(target=stat.voight["italian",], 
                   sumstat=stat.3pops.sim[models=="bott",],
                   statistic=mean, nb.replicate=100) 
plot(res.gfit.bott, main="Histogram under H0")

 res.gfit.exp=gfit(target=stat.voight["italian",], 
                   sumstat=stat.3pops.sim[models=="exp",], 
                   statistic=mean, nb.replicate=100) 
 res.gfit.const=gfit(target=stat.voight["italian",], 
                     sumstat=stat.3pops.sim[models=="const",], 
                     statistic=mean, nb.replicate=100) 
 summary(res.gfit.bott)
 
 summary(res.gfit.exp)
 summary(res.gfit.const)
 gfitpca(target=stat.voight["italian",], 
         sumstat=stat.3pops.sim, index=models, cprob=.1)
 
  require(abc.data) 
 data(ppc) 
 mylabels <- c("Mean nucleotide diversity","Mean Tajima's D", "Var Tajima's D") 
 par(mfrow = c(3,1), mar=c(5,2,4,0))
 for (i in c(1:3)){
   hist(post.bott[,i],breaks=40, xlab=mylabels[i], main="") 
   abline(v = stat.voight["italian", i], col = 2) 
 }
 
 stat.italy.sim <- subset(stat.3pops.sim, subset=models=="bott") 
 head(stat.italy.sim)
 head(par.italy.sim)
  cv.res.rej <- cv4abc(data.frame(Na=par.italy.sim[,"Ne"]),
                       stat.italy.sim, nval=10,  
                       tols=c(.005,.01, 0.05), method="rejection") 
  cv.res.reg <- cv4abc(data.frame(Na=par.italy.sim[,"Ne"]), 
                       stat.italy.sim, nval=10,  
                       tols=c(.005,.01, 0.05), method="loclinear") 
 summary(cv.res.rej)
 summary(cv.res.reg)
  par(mfrow=c(1,2), mar=c(5,3,4,.5), cex=.8) 
  plot(cv.res.rej, caption="Rejection") 
 plot(cv.res.reg, caption="Local linear regression")
  res <- abc(target=stat.voight["italian",], 
             param=data.frame(Na=par.italy.sim[, "Ne"]), 
             sumstat=stat.italy.sim, tol=0.05, 
             transf=c("log"), method="neuralnet")
 
 res
 summary(res)
par(mfrow=c(2,1),cex=.8) 
 hist(res)
 plot(res, param=par.italy.sim[, "Ne"])
```

# EasyABC

## Model

Let's consider a stochastic individual-based model to demonstrate how `EasyABC` can be used. This model is drawn from Jabot (2010), representing the stochastic dynamics of an ecological community. 

Each species in the community are given by a local competitive ability as determined by a filtering function of one quantitative trait $t$: $F(t)=1+A\exp\bigg(\frac{-(t-h)^2}{2\sigma^2}\bigg)$. At each time step, one individual drawn at random dies in a local community of size $J$. It is replaced either by an immigrant from the regional pool with probability $\frac{I}{I+J-1}$ or by the descendant of a local individual. Parameter $I$ measures the amount of immigration from the regional pool into the local community. The probability that the replacing individual is of species $i$ is proportional to the abundance of this species in the local community multiplied by its local competitive ability $F_i$. Here, the parameters of interest are $I,h,A,\sigma$ and the local community size $J$ is fixed at 500. The summary statistics are species richness of the community, Shannon's index, the mean of the trait value among individuals and the skewness of the trait value distribution. The model is a built-in model in this package.

## ABC schemes

There are 4 types of schemes available in `EasyABC`: standard rejection algorithm, sequential schemes, coupled to MCMC sequential schemes and a Simulated Annealing algorithm, implemented by `ABC_rejection(), ABC_sequential(), ABC_mcmc()` and `SABC()`, respectively.

All these functions require a model used to generate data and return a set of summary statistics, prior distributions, summary statistics from the observed data. 

In our example, we have summary statistics of the observed data 
```{r summarystat,cache=TRUE}
sum_stat_obs <- c(richness=100,shannon=2.5,meantrait=20,skewness=30000)
```
and assume prior distributions 
```{r abc,cache=TRUE}
trait_prior <- list(c("unif",3,5),
                   c("unif",-2.3,1.6),
                   c("unif",-25,125),
                   c("unif",-.7,3.2))
```


First, let's look at the abc rejection algorithm. 
```{r abcrejection,cache=TRUE}
set.seed(9)
(ABC_rej <- ABC_rejection(model=trait_model, prior=trait_prior,nb_simul=100,
                         summary_stat_target=sum_stat_obs,tol=.1,
                         use_seed=TRUE))
```

```{r}
trDens <- function(pr,n=100000) {
    lapply(pr,
           function(x)
               do.call(paste0("r",x[1]),
                       as.list(c(n,as.numeric(x[2:3])))))
}
par(mfrow=c(2,2))
mapply(function(x,y) {
           plot(density(x)); lines(density(y),col=2);
           rug(y,col=2)
       },
       trDens(trait_prior),
       split(ABC_rej$stats,col(ABC_rej$stats)))
```

Here, the `tol` is the percentage of simulations that are nearest the
observed summary statistics. The model must be a R function, taking a
vector of model parameter values as arguments and return a vector of
summary statistics. The available prior distribution are uniform,
normal, lognormal and exponential.


```{r histplot,cache=TRUE,echo=FALSE}
abchist <- function(ABC)
  {
par(mfrow=c(2,2))
labs <- c("I","A","h","sigma")
for (i in 1:4)
  hist(ABC$par[,i],main=paste("histogram of",labs[i]),xlab=labs[i])
  }
```


ABC rejection algorithm is computationally inefficient.


The idea of ABC-MCMC is to perform a Metropolis-Hastings algorithm to
explore e parameter space, and in replacing the step of likelihood
ratio computation by simulations of the model.

```{r abcmcmc_marjoram1,cache=TRUE,message=FALSE}
ABC_Marjoram_original<-ABC_mcmc(method = "Marjoram_original",
                                model = trait_model,
                                prior = trait_prior,
                                summary_stat_target = sum_stat_obs,
                                n_rec=10, use_seed=T,dist_max=0.2)
ABC_Marjoram_original
```



Wegmann et al.(2009) proposed a number of improvements by perform a calibration step so that the algorithm automatically determines the tolerance threshold, the scaling of the summary statistics and the scaling of the jumps in the parameter space during the MCMC. 

```{r abcmcmc_marjoram2,cache=TRUE}
ABC_Marjoram<-ABC_mcmc(method = "Marjoram", model=trait_model,
                       prior=trait_prior,summary_stat_target=sum_stat_obs,
                       n_rec=10,n_calibration=10,tolerance_quantile=0.2,
                       use_seed=T)
ABC_Marjoram
```



Wegmann et al.(2009) also proposed additional modification, among which a partial least squares transformation of the summary statistics.

```{r abcmcmc_wegmann,cache=TRUE}
ABC_Wegmann <-ABC_mcmc(method="Wegmann",model=trait_model,
                       prior=trait_prior,summary_stat_target=sum_stat_obs,
                       n_rec=10,n_calibration=10,
                       tolerance_quantile=.2,use_seed=T)
ABC_Wegmann
```




Sequential algorithms aim at reducing the required number of simulations to reach a given quality of the posterior approximation. The underlying idea is to spend more time in the areas of the parameter space where simulation are frequently close to the target. Sequential algorithms consist in a first step of standard rejection ABC, followed by a number of steps where the sampling of the parameter space is the accepted parameter values in the previous iteration. There are 4 algorithms to perform sequential sampling schemes for ABC. Sequential sampling schemes have been shown to be more efficient than standard rejection-based procedures.


```{r abcsequential,cache=TRUE}
ABC_Beaumont <- ABC_sequential(method="Beaumont", model=trait_model,
                               prior=trait_prior,nb_simul=10,
                               summary_stat_target=sum_stat_obs,
                               tolerance=c(8,5),use_seed=T)
ABC_Beaumont
```
This method is in fact the ABC population Monte Carlo algorithm.

```{r abcseq_Drovandi,cache=TRUE}
ABC_Drovandi<-ABC_sequential(method="Drovandi", model=trait_model, prior=trait_prior,nb_simul=10, summary_stat_target=sum_stat_obs, tolerance_tab=3, c=.7,use_seed=TRUE)
ABC_Drovandi
```

```{r abcseq_Delmoral,cache=TRUE}
ABC_Delmoral<-ABC_sequential(method="Delmoral",model=trait_model,
                             prior=trait_prior,
                             nb_simul =10, summary_stat_target=sum_stat_obs,
                             alpha=.5,
                             tolerance=3,use_seed=T)
ABC_Delmoral
```
This is an adaptive sequential Monte Carlo method.


```{r abcseq_Lenormand,cache=TRUE}
ABC_Lenormand <- ABC_sequential(method="Lenormand",model=trait_model,
                                prior=trait_prior,nb_simul=10,
                                summary_stat_target=sum_stat_obs,
                                p_acc_min=.4,
                                use_seed=T)
ABC_Lenormand
```

```{r dataframe,cache=TRUE}
mList <- list(rejection=ABC_rej,
              Marjoram_orig=ABC_Marjoram_original,
              Marjoram=ABC_Marjoram,
              Wegmann=ABC_Wegmann,
              Beaumont=ABC_Beaumont,
              Drovandi=ABC_Drovandi,
              Delmoral=ABC_Delmoral,
              Lenormand=ABC_Lenormand)

resAll <- ldply(mList,
      function(x) {
          melt(x$par)
      })

theme_set(theme_bw())
ggplot(resAll,aes(value))+geom_histogram()+
    facet_grid(.id~X2,scale="free")+
        theme(panel.margin=grid::unit(0,"lines"))

```


# Exercise

1. Try the socks example by the two packages
```{r socks,cache=TRUE}
sim_sock <- function(nb.mu,nb.sd,beta.a,beta.b){
# n_socks is positive and discrete, we can use Possion 
#  (problemic: mean and variance is same)
# or use negative binomal
# suppose we have a family of 4 and each person changes socks 
#  around 5 times a week, so we would have 20 
# pairs of socks, so your mean is 20*2 = 40. our sd could be 15 
prior_mu <- nb.mu
prior_sd <- nb.sd
prior_size <- prior_mu^2/(prior_sd^2-prior_mu)
n_socks <-rnbinom(1,mu=prior_mu,size=prior_size)
# proprotion of socks that are pair is Beta with a=2, b=2
prop_pairs <- rbeta(1,shape1=beta.a,shape2=beta.b)
n_pairs <- round(n_socks/2*prop_pairs)
n_odd <- n_socks-n_pairs*2
n_picked <- 11
socks <- rep(seq_len(n_pairs+n_odd),rep(c(2,1),c(n_pairs,n_odd)))
picked_socks<-sample(socks,size=min(n_picked,n_socks))
sock_counts <- table(picked_socks)
c(unique=sum(sock_counts==1),pairs=sum(sock_counts==2),nsocks=n_socks,npairs=n_pairs,nodd=n_odd,
  proppairs=prop_pairs)
}
simdata = data.frame(t(replicate(100000,sim_sock(40,15,2,2))))
```

2. Play the functions with toy model:
```{r toymodel,cache=TRUE}
toy_model <- function(x) {2*x+5+rnorm(1,0,0.1)}
toy_prior <- list(c("unif",0,1))
```

3. Suppose a state-space model is given by 
$N(t+1) \sim Normal(N(t) + b, \sigma_{proc}^2)$,
$N_{obs}(t) \sim Normal(N(t), \sigma_{obs}^2)$. 
The parameters of interest are $b, \sigma_{proc}^2, \sigma_{obs}^2,N(0)$.
Suppose your true parameter values are $b=3,\sigma_{proc}^2=1, \sigma_{obs}^2=1.2, N(0)=100$. Simulate a data set as your observed data and obtain the summary statistics mean and standard deviation. 
Then use the model and different prior distributions to see how different abc schemes work.
